{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV5d0ASvvt/1z3mHDaE7uC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MBilalSharif/RAG-based-CV-Reader/blob/main/CV_Reader_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvVTwIwnrau1"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community chromadb sentence-transformers pypdf google-generativeai\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directly use your CV file\n",
        "cv_filename = \"M.Bilal Sharif.pdf\"\n",
        "print(f\"‚úÖ Using CV file: {cv_filename}\")"
      ],
      "metadata": {
        "id": "DnY5SgmmrcnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "if cv_filename.endswith('.pdf'):\n",
        "    loader = PyPDFLoader(cv_filename)\n",
        "    documents = loader.load()\n",
        "elif cv_filename.endswith('.txt'):\n",
        "    loader = TextLoader(cv_filename)\n",
        "    documents = loader.load()\n",
        "else:\n",
        "    with open(cv_filename, 'r') as f:\n",
        "        documents = [Document(page_content=f.read())]\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s)\")\n",
        "print(f\"Total characters: {sum(len(doc.page_content) for doc in documents)}\")"
      ],
      "metadata": {
        "id": "JRm64E6qrqdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "#Chunking doc\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Created {len(chunks)} chunks\")"
      ],
      "metadata": {
        "id": "7kLhAkinr1ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Creating embeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "print(\"Creating vector database...\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./cv_vectorstore\"\n",
        ")\n",
        "print(\"Vector database created!\")"
      ],
      "metadata": {
        "id": "JaOwU3Nhr7HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "api_key = getpass(\"üîë Paste your Google AI API key: \")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name='models/gemini-2.5-flash',\n",
        "    generation_config={\n",
        "        'temperature': 0.3,\n",
        "        'max_output_tokens': 500,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Gemini ready!\")"
      ],
      "metadata": {
        "id": "gwJRLRvGsRvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_cv_question(question, k=5):\n",
        "    \"\"\"Ask a question about your CV using RAG\"\"\"\n",
        "\n",
        "\n",
        "    print(f\"üîç Searching for relevant info...\")\n",
        "    relevant_docs = vectorstore.similarity_search(question, k=k)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "    print(f\"‚úÖ Found {len(relevant_docs)} relevant sections\\n\")\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"You must respond with ONLY the answer, nothing else.\n",
        "\n",
        "CV Information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Rules:\n",
        "1. Extract the exact answer from the CV\n",
        "2. Do NOT add any preamble like \"The answer is\" or \"According to\"\n",
        "3. Do NOT add explanations\n",
        "4. Just state the fact directly\n",
        "\n",
        "Example:\n",
        "Question: What is the person's email?\n",
        "Bad: \"The person's email address is john@example.com\"\n",
        "Good: \"john@example.com\"\n",
        "\n",
        "Question: What is the person's name?\n",
        "Bad: \"According to the CV, the person's name is John Doe\"\n",
        "Good: \"John Doe\"\n",
        "\n",
        "Now answer the actual question above with just the direct answer:\"\"\"\n",
        "\n",
        "    print(\"ü§ñ Generating answer...\\n\")\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        answer = response.text.strip()\n",
        "    except Exception as e:\n",
        "        answer = f\"Error: {str(e)}\"\n",
        "\n",
        "    # Display result\n",
        "    print(\"=\"*60)\n",
        "    print(f\"‚ùì Question: {question}\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üí° Answer: {answer}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return answer\n",
        "\n",
        "print(\"‚úÖ RAG function ready!\")"
      ],
      "metadata": {
        "id": "VPJvpO6xss57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_cv_question(\"Give a short summary of CV?\", k=10)"
      ],
      "metadata": {
        "id": "QOfwqr1fsxj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}