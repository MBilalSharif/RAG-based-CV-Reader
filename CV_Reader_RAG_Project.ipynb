{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQiS6kn1DkC6COFjbqFGwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MBilalSharif/RAG-based-CV-Reader/blob/main/CV_Reader_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvVTwIwnrau1"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community chromadb sentence-transformers pypdf google-generativeai\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directly use your CV file\n",
        "cv_filename = \"M.Bilal Sharif.pdf\"\n",
        "print(f\"âœ… Using CV file: {cv_filename}\")"
      ],
      "metadata": {
        "id": "DnY5SgmmrcnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "if cv_filename.endswith('.pdf'):\n",
        "    loader = PyPDFLoader(cv_filename)\n",
        "    documents = loader.load()\n",
        "elif cv_filename.endswith('.txt'):\n",
        "    loader = TextLoader(cv_filename)\n",
        "    documents = loader.load()\n",
        "else:\n",
        "    with open(cv_filename, 'r') as f:\n",
        "        documents = [Document(page_content=f.read())]\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s)\")\n",
        "print(f\"Total characters: {sum(len(doc.page_content) for doc in documents)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "JRm64E6qrqdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "for doc in documents:\n",
        "    text = doc.page_content\n",
        "\n",
        "    text = re.sub(r'(?<=\\w)\\s(?=\\w)', '', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    text = re.sub(r'\\s+([.,;:!?])', r'\\1', text)\n",
        "\n",
        "    doc.page_content = text.strip()\n",
        "\n",
        "full_text = ' '.join([doc.page_content for doc in documents])\n",
        "\n",
        "\n",
        "full_text = full_text.replace('\\n', ' ')\n",
        "\n",
        "full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
        "\n",
        "documents = [Document(page_content=full_text)]"
      ],
      "metadata": {
        "id": "zk5rb1UOUCRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "#Chunking doc\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Created {len(chunks)} chunks\")"
      ],
      "metadata": {
        "id": "7kLhAkinr1ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Creating embeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "print(\"Creating vector database...\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./cv_vectorstore\"\n",
        ")\n",
        "print(\"Vector database created!\")"
      ],
      "metadata": {
        "id": "JaOwU3Nhr7HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriver = vectorstore.as_retriever(search_type='similarity' ,search_kwargs={\"k\":1} )\n",
        "print(\"Retriver ready!\")"
      ],
      "metadata": {
        "id": "9aPKNV3aQ3np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriver.invoke(\"Summary of CV\")"
      ],
      "metadata": {
        "id": "mAjq2ixPRo9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "api_key = getpass(\"ðŸ”‘ Paste your Google AI API key: \")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name='models/gemini-2.5-flash',\n",
        "    generation_config={\n",
        "        'temperature': 0.3,\n",
        "        'max_output_tokens': 500,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Gemini ready!\")"
      ],
      "metadata": {
        "id": "gwJRLRvGsRvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "    You are a helpful assistant\n",
        "    Answer only from the provided context\n",
        "    If the context is insufficent , just say you don't know the answer.\n",
        "\n",
        "    {context}\n",
        "    Question:{question}\n",
        "    \"\"\",\n",
        "    input_variables=['context','question']\n",
        ")"
      ],
      "metadata": {
        "id": "VPJvpO6xss57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'What is the name of Student in CV?'\n",
        "retrieved_docs = retriver.invoke(question)"
      ],
      "metadata": {
        "id": "XGzGoIU495XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"n\\n\".join(doc.page_content for doc in retrieved_docs)"
      ],
      "metadata": {
        "id": "CUD30Ce4_JUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.format(context=context_text, question=question)"
      ],
      "metadata": {
        "id": "2kwVQIqP_Lk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(final_prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "QOfwqr1fsxj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}